{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vishnu Menon\n",
    "### MIDI Music Generator\n",
    "### 5/19/2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports 1\n",
    "import pandas as pd \n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Activation\n",
    "from music21 import *\n",
    "import pretty_midi\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## File lists\n",
    "paths = ['Fantasie_Impromptu.mid', 'Solo_Violin_Sonata_No._1_in_G_Minor_-_J._S._Bach_BWV_1001.mxl',\n",
    "         'Moonlight_Sonata_3rd_Movement_-_Ludwig_van_Beethoven.mxl', 'Paganini_Caprice_No_5_in_A_minor.mxl',\n",
    "        'Liszt_Romance_S._169.mxl']\n",
    "## Includes vitali chaconne in addition to paths\n",
    "paths2 = ['Solo_Violin_Sonata_No._1_in_G_Minor_-_J._S._Bach_BWV_1001.mxl',\n",
    "         'Moonlight_Sonata_3rd_Movement_-_Ludwig_van_Beethoven.mxl', 'Paganini_Caprice_No_5_in_A_minor.mxl',\n",
    "          'Vitali_Chaconne_Solo_Violin.mxl', 'Liszt_Romance_S._169.mxl','Fantasie_Impromptu.mxl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get notes and rests per instrument from score\n",
    "def notesAndRests(score):\n",
    "    instruments = instrument.partitionByInstrument(score)\n",
    "    noteMatrix = []\n",
    "    i = instruments[0]\n",
    "    for NoteRestChord in i.notesAndRests:\n",
    "        noteMatrix.append(NoteRestChord)\n",
    "    return noteMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Replace noteMatrix with matrix containing tuples of pitch-offset information\n",
    "## Pitches are used from this point on to identify recreate chords based on offset information because some notes,\n",
    "## though in the same chord, can have varying durations. Note offsets in chords can also have discrepancies based\n",
    "## on the file's condition. Pairing pitches to the offset of the chord they originate from avoids this. \n",
    "def pitchesAndOffsetTuples(score):\n",
    "    for i in range(len(score)):\n",
    "        element = score[i]\n",
    "        pitchInfo = [element]\n",
    "        if(element.isChord):\n",
    "            pitchInfo = list(element.pitches)\n",
    "        elif(element.isNote):\n",
    "            pitchInfo = [element.pitch]\n",
    "        score[i] = (pitchInfo, element.offset)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group pitches occuring at same offset into pitch-duration tuples\n",
    "## Reconstruct the duration of a set of pitches to be added to the regrouped chords and notes\n",
    "def groupPitchesByOffset(tupleArray):\n",
    "    pitchesAndDuration = []\n",
    "    arrayLen = len(tupleArray)\n",
    "    i = 0\n",
    "    while(i < arrayLen):\n",
    "        pitches,offset = tupleArray[i]\n",
    "        while(i + 1 < arrayLen and tupleArray[i + 1][1] == offset):\n",
    "            i += 1\n",
    "            # Add all of the pitches in the tuple with the same offset as tuple i to this offset's group of pitches\n",
    "            if(len(tupleArray[i][0]) > 1  or type(tupleArray[i][0][0]) != type(note.Rest())):\n",
    "                pitches.extend(tupleArray[i][0])\n",
    "        dur = duration.Duration(quarterLength=4.0)\n",
    "        if(i < arrayLen - 1):\n",
    "            dur.quarterLength = tupleArray[i + 1][1] - offset\n",
    "        if(type(pitches[0]) == type(note.Rest()) and len(pitches) > 1):\n",
    "            pitches.pop(0)\n",
    "        pitchesAndDuration.append((pitches,dur))\n",
    "        i += 1\n",
    "    return pitchesAndDuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reconstruct notes and chords from the pitches and durations, used to test if the data is still faithful\n",
    "## to the original piece. \n",
    "def reconstructListOfNotesAndDurations(tuplesArray):\n",
    "    ## [] can be replaced by stream.Stream to create a stream instead of a list\n",
    "    s = []\n",
    "    for each in tuplesArray:\n",
    "        pitches, d = each\n",
    "        if(len(pitches) == 1 and type(pitches[0]) == type(note.Rest())):\n",
    "            element = pitches[0]\n",
    "        else:\n",
    "            pitchNames = list(map(lambda x: x.nameWithOctave, pitches))\n",
    "            if(len(pitchNames) > 1):\n",
    "                element = chord.Chord(pitchNames)\n",
    "            else:\n",
    "                element = note.Note(pitchNames[0])\n",
    "        element.duration = d\n",
    "        s.append(element)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert note-dur list to midi only multi label encoding\n",
    "def noteToMidiNumbers(nList):\n",
    "    # 88 to represent 88 midi encodings and 1 for rest\n",
    "    data = np.zeros((len(nList), 102))\n",
    "    for i in range(len(nList)):\n",
    "        if(nList[i].isRest):\n",
    "            data[i,88] = 1\n",
    "        else:\n",
    "            pitches = nList[i].pitches\n",
    "            for e in pitches:\n",
    "                data[i,e.midi] = 1\n",
    "                ## REMOVE THIS IF YOU WANT TO ENCODE ALL NOTES IN A CHORD NOT JUST THE FIRST\n",
    "                break\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert note-dur to midi with duration encoding\n",
    "def noteToMidiDur(nList):\n",
    "    # 130 to represent 128 midi encodings, 1 for rest, and 1 for duration\n",
    "    data = np.zeros((len(nList), 130))\n",
    "    for i in range(len(nList)):\n",
    "        if(nList[i].isRest):\n",
    "            data[i,128] = 1\n",
    "        else:\n",
    "            pitches = nList[i].pitches\n",
    "            for e in pitches:\n",
    "                data[i,e.midi] = 1\n",
    "        data[i,129] = nList[i].duration.quarterLength\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(score):\n",
    "        intermediate = notesAndRests(score)\n",
    "        intermediate = pitchesAndOffsetTuples(intermediate)\n",
    "        intermediate = groupPitchesByOffset(intermediate) \n",
    "        intermediate = reconstructListOfNotesAndDurations(intermediate)\n",
    "        intermediate = noteToMidiNumbers(intermediate)\n",
    "        print('''Number of notes: {0}'''.format(intermediate.shape[0]))\n",
    "        return intermediate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Group Multi-Label Encodings into Sequences and Corresponding Labels\n",
    "\n",
    "## Consider altering function so that sequences can be found at halfway points between labels recursively up to a \n",
    "## certain depth. E.g. Sequences at every 0th offset, Seqlen/2 offset, SeqLen/4 offset, and so on. \n",
    "def getSeqsAndLabelsForSingleScore(data, SeqLen):\n",
    "    ## data is a 2d numpy array, SeqLen is an integer\n",
    "    numSeqs = math.floor(data.shape[0]/(SeqLen + 1))\n",
    "    ## Numpy array of Seqs\n",
    "    bridgeAddition = math.floor(numSeqs - math.floor(SeqLen/2) / SeqLen)\n",
    "    SeqSet = np.zeros((numSeqs + bridgeAddition, SeqLen, data.shape[1]))\n",
    "    ## Numpy array of Labels\n",
    "    SeqLabels = np.zeros((numSeqs + bridgeAddition, data.shape[1]))\n",
    "    for i in range(numSeqs - 1):\n",
    "        SeqSet[i] = data[i*SeqLen : (i+1)*SeqLen]\n",
    "        SeqLabels[i] = data[(i+1)*SeqLen]\n",
    "    offset = math.floor(SeqLen/2)\n",
    "    for i in range(numSeqs, numSeqs + bridgeAddition - 1):\n",
    "        multiple = i - numSeqs\n",
    "        SeqSet[i] = data[offset + multiple*SeqLen : offset + (multiple + 1)*SeqLen]\n",
    "        SeqLabels[i] = data[offset + (multiple + 1)*SeqLen]\n",
    "    return (SeqSet, SeqLabels)\n",
    "\n",
    "## Every increasing permutation instead of every half sequence len\n",
    "def getSeqsAndLabelsPermutations(data, SeqLen):\n",
    "    ## data is a 2d numpy array, SeqLen is an integer\n",
    "    numSeqs = math.floor(data.shape[0] - SeqLen)\n",
    "    ## Numpy array of Seqs\n",
    "    SeqSet = np.zeros((numSeqs, SeqLen, data.shape[1]))\n",
    "    ## Numpy array of Labels\n",
    "    SeqLabels = np.zeros((numSeqs, data.shape[1]))\n",
    "    for i in range(numSeqs):\n",
    "        SeqSet[i] = data[i : i + SeqLen]\n",
    "        SeqLabels[i] = data[i + SeqLen]\n",
    "    return (SeqSet, SeqLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of notes: 1609\n",
      "(1559, 50, 102) (1559, 102)\n",
      "Number of notes: 2745\n",
      "(4254, 50, 102) (4254, 102)\n",
      "Number of notes: 2872\n",
      "(7076, 50, 102) (7076, 102)\n",
      "Number of notes: 318\n",
      "(7344, 50, 102) (7344, 102)\n",
      "Number of notes: 576\n",
      "(7870, 50, 102) (7870, 102)\n",
      "Overall shape of sequences data (7870, 50, 102)\n"
     ]
    }
   ],
   "source": [
    "## Outputs a ndarray of (Num Sequences, Sequence Length, Num features) schema\n",
    "def getSeqsAndLabels(scores, SeqLen):\n",
    "    SeqSet, SeqLabels = getSeqsAndLabelsPermutations(getData(scores.pop(0)), SeqLen)\n",
    "    print(SeqSet.shape, SeqLabels.shape)\n",
    "    for each in scores:\n",
    "        D, L = getSeqsAndLabelsPermutations(getData(each), SeqLen)\n",
    "        SeqSet = np.concatenate((SeqSet, D))\n",
    "        SeqLabels = np.concatenate((SeqLabels, L))\n",
    "        print(SeqSet.shape, SeqLabels.shape)\n",
    "    return (SeqSet, SeqLabels)\n",
    "# Load Files and Extract streams\n",
    "scores = list(map(lambda x: converter.parse(x).parts.stream(), paths))\n",
    "Seqs, Labels = getSeqsAndLabels(scores, 50)\n",
    "print('''Overall shape of sequences data {0}'''.format(Seqs.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Model\n",
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "    256,\n",
    "    input_shape=(Seqs.shape[1], Seqs.shape[2]),\n",
    "    return_sequences=True\n",
    "))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dense(Seqs.shape[2], activation = 'softmax'))\n",
    "model.compile(loss='s_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "7860/7860 [==============================] - 113s 14ms/step - loss: 3.4033 - accuracy: 0.1020\n",
      "Epoch 2/80\n",
      "7860/7860 [==============================] - 119s 15ms/step - loss: 3.0343 - accuracy: 0.1560\n",
      "Epoch 3/80\n",
      "7860/7860 [==============================] - 117s 15ms/step - loss: 2.8132 - accuracy: 0.1842\n",
      "Epoch 4/80\n",
      "7860/7860 [==============================] - 122s 16ms/step - loss: 2.6673 - accuracy: 0.2043\n",
      "Epoch 5/80\n",
      "7860/7860 [==============================] - 133s 17ms/step - loss: 2.5433 - accuracy: 0.2207\n",
      "Epoch 6/80\n",
      "7860/7860 [==============================] - 133s 17ms/step - loss: 2.4321 - accuracy: 0.2421\n",
      "Epoch 7/80\n",
      "7860/7860 [==============================] - 139s 18ms/step - loss: 2.3296 - accuracy: 0.2711\n",
      "Epoch 8/80\n",
      "7860/7860 [==============================] - 136s 17ms/step - loss: 2.2354 - accuracy: 0.2874\n",
      "Epoch 9/80\n",
      "7860/7860 [==============================] - 141s 18ms/step - loss: 2.1423 - accuracy: 0.3069\n",
      "Epoch 10/80\n",
      "7860/7860 [==============================] - 142s 18ms/step - loss: 2.0256 - accuracy: 0.3478\n",
      "Epoch 11/80\n",
      "7860/7860 [==============================] - 141s 18ms/step - loss: 1.8998 - accuracy: 0.3802\n",
      "Epoch 12/80\n",
      "7860/7860 [==============================] - 135s 17ms/step - loss: 1.7706 - accuracy: 0.4248\n",
      "Epoch 13/80\n",
      "7860/7860 [==============================] - 135s 17ms/step - loss: 1.6340 - accuracy: 0.4734\n",
      "Epoch 14/80\n",
      "7860/7860 [==============================] - 142s 18ms/step - loss: 1.4997 - accuracy: 0.5172\n",
      "Epoch 15/80\n",
      "7860/7860 [==============================] - 202s 26ms/step - loss: 1.3750 - accuracy: 0.5672\n",
      "Epoch 16/80\n",
      "7860/7860 [==============================] - 213s 27ms/step - loss: 1.2344 - accuracy: 0.6130\n",
      "Epoch 17/80\n",
      "7860/7860 [==============================] - 220s 28ms/step - loss: 1.1102 - accuracy: 0.6492\n",
      "Epoch 18/80\n",
      "7860/7860 [==============================] - 204s 26ms/step - loss: 0.9838 - accuracy: 0.6973\n",
      "Epoch 19/80\n",
      "7860/7860 [==============================] - 195s 25ms/step - loss: 0.8694 - accuracy: 0.7286\n",
      "Epoch 20/80\n",
      "7860/7860 [==============================] - 196s 25ms/step - loss: 0.7615 - accuracy: 0.7684\n",
      "Epoch 21/80\n",
      "7860/7860 [==============================] - 202s 26ms/step - loss: 0.6589 - accuracy: 0.8064\n",
      "Epoch 22/80\n",
      "7860/7860 [==============================] - 197s 25ms/step - loss: 0.5626 - accuracy: 0.8379\n",
      "Epoch 23/80\n",
      "7860/7860 [==============================] - 205s 26ms/step - loss: 0.4791 - accuracy: 0.8684\n",
      "Epoch 24/80\n",
      "7860/7860 [==============================] - 212s 27ms/step - loss: 0.4030 - accuracy: 0.8902\n",
      "Epoch 25/80\n",
      "7860/7860 [==============================] - 196s 25ms/step - loss: 0.3353 - accuracy: 0.9156\n",
      "Epoch 26/80\n",
      "7860/7860 [==============================] - 200s 25ms/step - loss: 0.2802 - accuracy: 0.9364\n",
      "Epoch 27/80\n",
      "7860/7860 [==============================] - 199s 25ms/step - loss: 0.2390 - accuracy: 0.9436\n",
      "Epoch 28/80\n",
      "7860/7860 [==============================] - 210s 27ms/step - loss: 0.1994 - accuracy: 0.9538\n",
      "Epoch 29/80\n",
      "7860/7860 [==============================] - 227s 29ms/step - loss: 0.1713 - accuracy: 0.9607\n",
      "Epoch 30/80\n",
      "7860/7860 [==============================] - 227s 29ms/step - loss: 0.1497 - accuracy: 0.9683\n",
      "Epoch 31/80\n",
      "7860/7860 [==============================] - 230s 29ms/step - loss: 0.1284 - accuracy: 0.9712\n",
      "Epoch 32/80\n",
      "7860/7860 [==============================] - 227s 29ms/step - loss: 0.1137 - accuracy: 0.9765\n",
      "Epoch 33/80\n",
      "7860/7860 [==============================] - 231s 29ms/step - loss: 0.0987 - accuracy: 0.9770\n",
      "Epoch 34/80\n",
      "7860/7860 [==============================] - 187s 24ms/step - loss: 0.0916 - accuracy: 0.9796\n",
      "Epoch 35/80\n",
      "7860/7860 [==============================] - 167s 21ms/step - loss: 0.0803 - accuracy: 0.9824\n",
      "Epoch 36/80\n",
      "7860/7860 [==============================] - 167s 21ms/step - loss: 0.0807 - accuracy: 0.9800\n",
      "Epoch 37/80\n",
      "7860/7860 [==============================] - 170s 22ms/step - loss: 0.0699 - accuracy: 0.9841\n",
      "Epoch 38/80\n",
      "7860/7860 [==============================] - 168s 21ms/step - loss: 0.0652 - accuracy: 0.9847\n",
      "Epoch 39/80\n",
      "7860/7860 [==============================] - 167s 21ms/step - loss: 0.0736 - accuracy: 0.9818\n",
      "Epoch 40/80\n",
      "7860/7860 [==============================] - 167s 21ms/step - loss: 0.0572 - accuracy: 0.9865\n",
      "Epoch 41/80\n",
      "5056/7860 [==================>...........] - ETA: 42s - loss: 0.0508 - accuracy: 0.9871"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-c85bcb878262>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Train on everything except the first 10 samples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSeqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mSeqs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mLabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## Train on everything except the first 10 samples\n",
    "model.fit(Seqs[10:Seqs.shape[0]], Labels[10:Labels.shape[0]], epochs=80, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75, 77, 73, 67, 68, 70, 77, 75, 75, 73, 80, 68, 70, 68, 69, 70, 72, 68, 96, 96, 94, 92, 88, 87, 85, 81, 82, 80, 76, 70, 80, 72, 69, 70, 75, 68, 70, 73, 72, 70, 68, 70, 70, 68, 73, 75, 77, 80, 78, 77, 75, 77, 75, 73, 75, 77, 73, 68, 70, 71, 71, 70, 75, 77, 78, 77, 75, 77, 73, 67, 68, 70, 77, 75, 75, 73, 80, 68, 70, 70, 69, 70, 72, 68, 96, 96, 27, 92, 88, 87, 85, 81, 82, 80, 76, 70, 80, 72, 69, 70, 75, 68, 70, 73, 72, 70, 68, 70, 70, 68, 73, 75, 77, 80, 78, 77, 75, 77, 75, 73, 75, 77, 73, 68, 70, 71, 71, 70, 75, 77, 78, 77, 75, 77, 73, 67, 68, 70, 77, 75, 75, 73, 80, 68, 70, 70, 69, 70, 72, 68, 84, 96, 94, 92, 88, 87, 85, 81, 82, 80, 76, 70, 80, 72, 69, 70, 75, 68, 70, 73, 72, 70, 68, 70, 70, 68, 73, 75, 77, 80, 78, 77, 75, 77, 75, 73, 75, 77, 73, 68, 70, 71, 71, 70, 75, 77, 78, 77, 75, 77]\n"
     ]
    }
   ],
   "source": [
    "## Pass in the number of notes you would like the model to predict as an int\n",
    "\n",
    "from numpy.random import choice\n",
    "\n",
    "def getPredictions(n):\n",
    "    inp = Seqs[698].tolist()\n",
    "    predictions = []\n",
    "    i = 0\n",
    "    while(i < n):\n",
    "        inpNP = np.asarray(inp)\n",
    "        pred = model.predict(np.reshape(inpNP, (1,inpNP.shape[0],inpNP.shape[1])))\n",
    "        ## Currently only chooses the maximum of the predicted array for storage\n",
    "        inp.append(pred[0])\n",
    "        draw = np.random.choice(np.arange(0,inpNP.shape[1]),p=pred[0], replace = True)\n",
    "        predictions.append(draw)\n",
    "        inp = inp[1:len(inp)]\n",
    "        i += 1        \n",
    "    return predictions\n",
    "predNotes = getPredictions(200)\n",
    "print(predNotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recreateStream(midis):\n",
    "    s = stream.Stream()\n",
    "    for m in midis:\n",
    "        p = pitch.Pitch(m)\n",
    "        n = note.Note()\n",
    "        n.pitch = p\n",
    "        n.duration = duration.Duration(quarterLength = 1)\n",
    "        s.append(n)\n",
    "    return s\n",
    "s = recreateStream(predNotes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Output.mid'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Write to midi file\n",
    "slStream = s.augmentOrDiminish(0.50)\n",
    "slStream.write('midi', fp='Output.mid')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
